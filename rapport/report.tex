\documentclass[12pt]{article}

%\usepackage[T1]{fontenc} % Support accents copy-pasting
\usepackage[utf8]{inputenc} % Input encoding
\usepackage[french]{babel}
\usepackage[a4paper,width=15cm,top=2.5cm,bottom=2.5cm]{geometry} % Size of the page

%\usepackage[ruled]{algorithm2e} % Algorithms
\usepackage{algcompatible}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{float} % H option
\usepackage{listings} % Typeset programs within the document
\usepackage{array,tabularx} % Extends tabular
\usepackage{amsmath,amsthm,amsfonts,amssymb} % Math
%\usepackage[bb=boondox]{mathalfa}
\usepackage{bbold}
\usepackage{braket} % For \Set
\usepackage{caption} % Caption options
\usepackage{subcaption} % For subfigures
\usepackage{graphicx} % For \includegraphics
\usepackage[export]{adjustbox} % Extends \includegraphics
\usepackage{tikz}
\PassOptionsToPackage{hyphens}{url} % Break urls at new lines
\usepackage{hyperref} % For hyperlinks
\usepackage{url} % For \url
\usepackage{svg} % To include svg images
\usepackage{mathtools} % for KL divergence

% Tikz options
\usetikzlibrary{positioning}
\usetikzlibrary{trees}
\usetikzlibrary{arrows,automata}
\usetikzlibrary{positioning}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{calc}
\usetikzlibrary{snakes}
\usetikzlibrary{shapes.arrows}

% Hyperlinks colors
\hypersetup{
	colorlinks,
	linkcolor={red!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}

% Numerotation depth in the document and in the table of contents
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}

% algorithm2e options
%\SetEndCharOfAlgoLine{}

% Command to specify the source of a figure on a new line
\newcommand{\source}[1]{\vspace{-5pt} \caption*{ Source: {#1}} }

% Command to number an equation in align* environment
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

% Color commands
\newcommand{\red}[1]{{\color{red}{#1}}}
\newcommand{\blue}[1]{{\color{blue}{#1}}}

% Math commands
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Mod}{\ \mathrm{mod}\ }
\newcommand*{\pd}[3][]{\ensuremath{\frac{\partial^{#1} #2}{\partial #3}}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\EE}[2]{\mathbb{E}_{#1\!\!}\left[#2\right]}
\newcommand{\CEE}[3]{\EE{#1}{{#2}~\middle\vert~{#3}}}
\def\E#1{\EE{\,}{#1}}
\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
	#1\;\delimsize\|\;#2%
}
\newcommand{\infdiv}{D\infdivx}
\def\Pr#1{{{\rm Pr\!}\left\{#1\right\}}}

% Theorems
\newtheorem{theorem}{Théorème}
\newtheorem{definition}{Définition}

\title{Projet d'Advanced Machine Learning : AdaBoost}
\date{\today}
\author{Charly Delfosse, Arnaud Palgen, Victor Dheur}

\begin{document}
	\maketitle
	
	\section*{Introduction}
	
	Dans le domaine du machine learning, on recherche l'hypothèse qui s'approche le plus d'une fonction
	cible. Cette recherche peut être couteuse en temps de calcul et si celle-ci est trop poussée, 
	l'hypothèse résultante pourrait être trop complexe et trop spécifique au jeu de données
	d'entrainement (tradeoff biais-complexité). Pour solutionner ces problèmes, on utilise le 
	boosting: une approche permettant d'augmenter les performances d'algorithmes de recherche 
	d'hypothèse simples (weak learners). Ce rapport explique le principe général du boosting,
	présente en détail l'algorithme de boosting AdaBoost, et montre
	les performances de celui-ci par rapport aux bornes sur l'erreur de généralisation.
	
	\section{Principe du boosting}
	
	Le boosting est une méthode permettant d'augmenter les performances\\ d'algorithmes weak learners
	(voir def.~\ref{def:weaklearner}). Cette méthode permet aussi de résoudre deux problèmes
	rencontrés lors de l'apprentissage:
	\begin{enumerate}
		\item Le tradeoff biais-complexité
		\item La complexité des calculs
	\end{enumerate}
	
	Le principe général du boosting consiste à commencer par une hypothèse de base,
	qui est ajustée à chaque itération de l'algorithme pour produire une hypothèse plus précise.
	
	\begin{definition}
	Soit $f: \mathcal{X} \rightarrow \mathcal{Y}$ la fonction cible de labellisation et $\mathcal{D}$
	une distribution des probabilités sur $\mathcal{X}$ qui assigne une probabilité à chaque élément
	de $\mathcal{X}$. On définit $L_{(\mathcal{D},f)}(h)$ comme étant l'erreur d'une hypothèse
	$h: \mathcal{X} \rightarrow \mathcal{Y}$ telle que
	$L_{(\mathcal{D},f)} = \underset{x \sim \mathcal{D}}{\mathbb{P}} [h(x) \neq f(x)]$.
	\end{definition}	
	
	\begin{definition} Un algorithme \textit{A} est un $\gamma$-weak learner pour une classe
		d'hypothèses $\mathcal{H}$ s'il existe une fonction $m_{\mathcal{H}}: (0,1) \rightarrow
		\mathbb{N}$ telle que, pour tout $\delta \in (0,1)$, pour toute distribution des probabilités
		$\mathcal{D}$ sur $\mathcal{X}$ et pour chaque fonction de labellisation binaire $f:\mathcal{X}
		\rightarrow \{\pm 1\}$, si on émet l'hypothèse qu'il existe une hypothèse $h \in \mathcal H$
		telle que $L_{D,f}(h)=0$, alors, lors de l'exécution de l'algorithme d'apprentissage sur
		$m \geq m_{\mathcal{H}}(\delta)$ exemples (indépendants et identiquement distribués) générés
		par $\mathcal{D}$ et labelisés par $f$, l'algorithme retourne, avec une probabilité
		$1- \delta$, une hypothèse \textit{h} tel que $L_{(\mathcal{D}, f)}(h) \leq \frac{1}{2} - \gamma$.
		\label{def:weaklearner}
	\end{definition}
	
	\renewcommand{\labelitemi}{$\bullet$}
	\section{AdaBoost}
	
	AdaBoost (adaptative boosting) est une technique de boosting très répandue. L'article \cite{Bousquet2003-oz} (chapitre 10) présente son fonctionnement. Dans cette section, on explique le principe d'AdaBoost et on présente son algorithme.  
	
	\subsection{Principe}
	
	Le principe d'AdaBoost est de modifier le processus d'apprentissage d'un weak learner pour que celui-ci se concentre sur les exemples les plus pertinents. AdaBoost va en fait itérer un certain nombre de fois le même procédé. A chaque étape, le weak learner s'entraine sur le même jeu de données mais ne considère pas de la même façon les exemples par rapport à l'étape précédente. Il se concentre en fait sur les exemples les plus problématiques, ceux-ci sont désignés par AdaBoost. AdaBoost répète ce procédé un certain nombre de fois et combine ensuite les différentes hypothèses obtenues à chaque étape pour fournir l'hypothèse finale. Le but d'AdaBoost est de tirer le meilleur profit possible du tradeoff biais-complexité en essayant d'avoir une hypothèse finale avec une erreur d'entrainement la plus petite possible sans être trop complexe.
	
	\subsection{Algorithme}
	
	On présente maintenant l'algorithme d'AdaBoost. On fournit d'abord une description étape par étape et on rentre ensuite dans les détails des points importants. Le pseudo-code du processus AdaBoost est repris par l'algorithme \ref{adaboost:algo}.
	
	\subsubsection{Description}
	
	Soit $f$ une fonction cible et $S=(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$ le jeu de données d'entrainement
	tel que $\forall 1 \leq i \leq m, f(x_i) = y_i$. Soit $T \geq 1$ un naturel représentant le nombre
	d'itérations de l'algorithme AdaBoost. D'abord, AdaBoost génère une distribution $D^{(0)} \in \mathbb{R}^m_+$
	telle que $\forall 1 \leq i \leq m, D^{(0)}_i = \frac{1}{m}$ (distribution équitable).
	Cette distribution représente l'importance que doit accorder le weak learner à chaque exemple.
	De fait, plus le poids $D^{(t)}_i$ ($1 \leq i \leq m$ et $1 \leq t \leq T$) est grand, plus
	celui-ci doit accorder d'importance à l'exemple $(x_i,y_i)$ et inversement. Une fois que cela
	est fait, AdaBoost va itérer $T$ fois le même procédé. A chaque itération, le weak learner
	s'entraine sur le jeu de données $S$. L'erreur d'entrainement $R_m(h_t)$ du weak learner $h_t$ est
	calculée selon $D^{(t)}$:
	\begin{equation}
		\label{adaboost:trainingerror}
		R_m(h_t) = \sum_{i=1}^m D^{(t)}_i \mathbb{1}_{[h_t(x_i) \neq y_i]}
	\end{equation}
	Comme on le voit dans (\ref{adaboost:trainingerror}), plus le poids d'un exemple (dans $D^{(t)}$) est grand, plus il a d'importance dans le calcul de l'erreur. De plus, par définition du weak learner, il y a une grande probabilité ($1- \delta$) que $R_m(h_t)< \frac{1}{2} - \gamma$. Ainsi, à l'itération $t$, le weak learner fournit une hypothèse $h_t$ et l'erreur $R_m(h_t)$ associée (\ref{adaboost:trainingerror}). AdaBoost détermine ensuite la nouvelle distribution $D^{(t+1)}$ (\ref{adaboost:newdistrib}) et passe à l'itération $t+1$. Une fois que les $T$ itérations sont terminées, AdaBoost combine les différentes hypothèses $h_t$ pour obtenir l'hypothèse finale $h$:
	\begin{equation}
		\label{adaboost:finalhypo}
		h(x) = sign (\sum_{t=1}^T w_t h_t(x))
	\end{equation}
	Dans (\ref{adaboost:finalhypo}), on remarque que l'hypothèse $h_t$ a un poids $w_t$.
	Celui-ci est en fait calculé à l'itération $t$ après le calcul de l'erreur:
	$w_t = \frac{1}{2} log(\frac{1}{R_m(h_t)} - 1)$. Plus l'erreur d'entrainement de l'hypothèse $h_t$
	est petite, plus elle aura d'importance dans l'hypothèse finale $h$ et inversement.
	AdaBoost essaie ainsi de donner plus d'importance aux hypothèses prometteuses qu'aux hypothèses
	moins performantes.
	
	
	\subsubsection{Modification de la distribution $D$}
	\label{adaboost:newdistrib}
	AdaBoost modifie donc la distribution $D^{(t)}$ après chaque itération: 
	\begin{equation}
		\label{adaboost:weights}
		\forall 1 \leq i \leq m, D^{(t+1)}_i = \frac{D^{(t)}_i e^{-w_t y_i h_t(x_i)}}{\sum_{j=1}^m D^{(t)}_j e^{-w_t y_j h_t(x_j)}} 
	\end{equation}   
	Dans (\ref{adaboost:weights}) on remarque que le nouveau poids $D^{(t+1)}_i$ de l'exemple $(x_i,y_i)$ est proportionnel à son ancien poids $D^{t}_i$, cela permet à AdaBoost de limiter la variance. De plus, si on suppose que $w_t > 0$ (ce qui est vrai dans la majorité des cas car $w_t > 0 \Leftrightarrow R_m(h_t) < \frac{1}{2}$ et il y a une probabilité supérieure à $1-\delta$ que cela soit vrai (en effet, $R_m(h_t) < \frac{1}{2} - \gamma$ avec une probabilité $1-\delta$)), on a que:
	\begin{itemize}
		\item si $sign(y_i)=sign(h_t(x_i))$ alors $e^{-w_t y_i h_t(x_i)} < 1$,
		\item si $sign(y_i) \neq sign(h_t(x_i))$ alors $e^{-w_t y_i h_t(x_i)} > 1$. 
	\end{itemize}
	Ainsi, si l'hypothèse $h_t$ avait fait la bonne prédiction pour l'exemple $(x_i,y_i)$ alors le nouveau poids $D^{(t+1)}_i$ sera plus grand que si elle s'était trompée. Cela est en accord avec le fait qu'AdaBoost incite le weak learner à se concentrer sur les exemples problématiques (et donc pertinents).
	Le dénominateur est uniquement là pour normaliser et assurer la définition de distribution: $\forall 1 \leq t \leq T, \sum_{i=1}^m D^t_i = 1$.
	
	
	\begin{algorithm}[H]
		\caption{AdaBoost}
		\label{adaboost:algo}
		\begin{flushleft}
			\textbf{INPUT:} $S=(x_1,y_1)(x_2,y_2),...,(x_m,y_m)$, le jeu de données d'entrainement,\\
			\hspace{1.5cm} $WL$, un weak learner,\\
			\hspace{1.5cm} $T$, un naturel (non nul) représentant le nombre d'itérations d'AdaBoost.\\
			\textbf{OUTPUT:} l'hypothèse finale $h_f$
		\end{flushleft}
		\begin{algorithmic}[1]
			\Function{$AdaBoost$}{$S,WL,T$}
			\State $D^{(1)}=(\frac{1}{m},...,\frac{1}{m})$
			\For {$t=1,...,T$}
			\State $h_t = WL(D^{(t)},S)$
			\State $R_m(h_t)= \sum_{i=1}^m D^{(t)}_i \mathbb{1}_{[h_t(x_i) \neq y_i]}$
			\State $w_t = \frac{1}{2} log(\frac{1}{E_t(h_t)} - 1)$
			\For {$i=1,...,m$}
			\State $D^{(t+1)}_i = \frac{D^{(t)}_i e^{-w_t y_i h_t(x_i)}}{\sum_{j=1}^m D^{(t)}_j e^{-w_t y_j h_t(x_j)}}$ 
			\EndFor
			\EndFor
			\State $h(x) = sign (\sum_{t=1}^T w_t h_t(x))$
			\State \Return {$h$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\section{Bornes sur l’erreur de généralisation}
	
	Nous montrons maintenant comment obtenir des bornes sur l'erreur de généralisation d'AdaBoost.
	Nous commençons par obtenir la dimension VC d'AdaBoost, puis nous appliquons une inégalité basée sur l'inégalité de Hoeffding.
	Le développement concernant la dimension VC est tiré du livre \cite{Shalev-Shwartz2014-ba}, et des détails supplémentaires ont été ajoutés.
	
	Nous avons vu que la sortie de l'algorithme AdaBoost est une hypothèse composée d'une combinaison linéaire de $T$ hypothèses $h_1, ..., h_T$ apprises par un weak learner.
	Nous dénotons l'espace d'hypothèses de ce weak learner par $B$.
	La sortie d'AdaBoost fait partie de cet ensemble d'hypothèses que nous nommons L(B, T) :
	\[
	L(B, T) = \Set{ x \mapsto \text{sign}\left( \sum_{t=1}^T w_t h_t(x) \right) \mid \forall t, w_t \in \R \land h_t \in B}.
	\]
	
	Pour un espace d'hypothèses $\mathcal{H}$, nous dénotons $d_{VC}(\mathcal{H})$ sa dimension VC et $m_{\mathcal{H}}$ sa growth function.
	
	\begin{theorem}{(Dimension VC d'AdaBoost)}
		
		Nous allons montrer que, lorsque $T \geq 3$ et $d_{VC}(B) \geq 3$ :
		\[
		d_{VC}(L(B, T)) \leq T(d_{VC}(B) + 1) (3 \ln(T (d_{VC}(B) + 1)) + 2).
		\]
	\end{theorem}

	\begin{proof}
	
	Dénotons $d = d_{VC}(B)$ et supposons que $T \geq 3$ et $d_{VC}(B) \geq 3$.
	Soit $C = (x_1, ..., x_m)$ une séquence de points qui est "shattered" par $L(B, T)$: chacun des $2^m$ labellings différents est générable par une hypothèse qui se trouve dans $L(B, T)$.
	La création d'un labeling de $C$ par une hypothèse $h \in L(B, T)$ se fait en 2 étapes.
	D'abord, $T$ hypothèses $h_1, ..., h_T \in B$ sont sélectionnées par le weak-learner.
	Ensuite, un vecteur $w \in \R^T$ permet de créer la combinaison linéaire $\sum_{t=1}^T w_t h_t(x)$ pour un point $x$.
	On obtient ainsi un labeling $(h(x_1), ..., h(x_m))$ de $C$.
	
	Nous allons utiliser le lemme de Sauer, qui permet de borner supérieurement la growth function $m_{\mathcal{H}}$ d'un espace d'hypothèses $\mathcal{H}$ en utilisant la VC dimension $d_{VC}(\mathcal{H})$ :
	\[
	m_{\mathcal{H}}(m) \leq \left( \frac{em}{d_{VC}(\mathcal{H})} \right) ^{d_{VC}(\mathcal{H})}.
	\]
	
	Par le lemme de Sauer, au plus $\left( \frac{em}{d} \right)^{d}$ labelings différents de $C$ peuvent être créés à partir de l'espace d'hypothèses $B$.
	De plus, $T$ hypothèses qui créent ces labelings doivent être choisies, ce qui donne au plus $\left( \frac{em}{d} \right) ^{d T}$ labelings différents.
	En utilisant encore le lemme de Sauer, puisque la dimension VC d'un perceptron (sans biais) dans $\R^T$ est de $T$, la combinaison linéaire entraîne $\left( \frac{em}{T} \right)^{T}$ labelings différents.
	Nous avons donc :
	\[
	m_{L(B, T)}(m) \leq \left( \frac{em}{d} \right) ^{d T} \left( \frac{em}{T} \right)^{T}.
	\]
	
	En utilisant les hypothèses que $T \geq 3$ et $d_{VC}(B) \geq 3$, nous avons :
	\[
	\left( \frac{em}{d} \right) ^{d T} \left( \frac{em}{T} \right)^{T} \leq m^{(d + 1) T}.
	\]
	
	Puisque $C$ est shattered par $L(B, T)$, $m_{L(B, T)}(m) = 2^m$.
	
	Nous avons donc :
	\[
	2^m = m_{L(B, T)}(m) \leq m^{(d + 1) T}
	\]
	
	En passant au log :
	\[
	m \leq \ln(m) \frac{(d + 1) T}{\ln(2)}
	\]
	
	Il est possible de montrer (voir \cite{Shalev-Shwartz2014-ba} p.419 lemme A.1) que
	\[
	\forall a > 0, x \leq a \ln(x) \implies x \leq 2 a \ln(a).
	\]
	
	On déduit de ce dernier lemme une borne sur $m$, qu'on borne encore par une expression plus simple :
	\[
	m \leq \frac{2 (d + 1) T}{\ln(2)} \ln \frac{(d + 1) T}{\ln(2)} \leq (d + 1) T (3 \ln((d + 1) T) + 2).
	\]
	
	En d'autres termes, le nombre de points $m$ qui peuvent être shattered par $L(B, T)$ est borné supérieurement par une expression qui dépend de $d$ et $T$.
	Puisque la dimension VC correspond au nombre maximum de points qui peuvent être shattered, l'expression reste vraie lorsque $m = d_{VC}(L(B, T))$ :
	\[
	d_{VC}(L(B, T)) \leq (d + 1) T (3 \ln((d + 1) T) + 2).
	\]
	\end{proof}

	Il ne reste plus qu'à borner l'erreur de généralisation en utilisant cette dimension VC.
	Il est possible de dériver une inégalité basée sur l'inégalité de Hoeffding qui tire profit de la growth function.
	Celle-ci est présentée dans \cite{Bousquet2003-oz} à la page 192 et est reprise à l'équation \ref{eq:vc_inequality}.
	Le lemme de Sauer permet de la borner par une expression dépendant de la dimension VC d'AdaBoost à l'équation \ref{eq:vc_inequality_sauer}.
	
	En supposant que la loss produit des valeurs bornées dans $[0, 1]$, pour toute précision $\epsilon > 0$, on obtient :
	\begin{align}
	\mathbb{P}\left[ \sup_{h \in L(B, T)} (R(h) - R_m(h)) \geq \epsilon \right] &\leq 4 m_{L(B, T)}(2 m) e^{-m \epsilon^2 / 8} \label{eq:vc_inequality} \\
	&\leq 4 \left( \frac{2 m e}{d_{VC}(L(B, T))} \right)^{d_{VC}(L(B, T))} e^{-m \epsilon^2 / 8}. \label{eq:vc_inequality_sauer}
	\end{align}

	Un point important de ce développement est que la dimension VC de l'ensemble des hypothèses produites par AdaBoost augmente linéairement avec la dimension VC de $B$ et avec $T$, en ignorant les facteurs constants et logarithmiques.
	
	\section{Conclusion}
	
	Le boosting est donc une approche très intéressante dans la recherche de la meilleure hypothèse tout en limitant la complexité et les temps de calcul. En particulier, l'algorithme Adaboost permet d'obtenir des résultats probants dans ce domaine. 	
	
	\bibliographystyle{alpha}
	\bibliography{report}
	
\end{document}