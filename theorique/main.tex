\documentclass[12pt, a4paper, draft]{article}
\usepackage{amsfonts}

\title{Un Titre}


\begin{document}
\maketitle

\section{Boosting}
p130
    Un outil d'apprentissage en machine learning
    
    permet de résoudre le problème du tradeoff biais-variance
    et le problème est la complexité des calculs de l'apprentissage.

    Un algo de boosting augmente la précision d'un weak learner.

    Probably Approximately Correct (PAC) learning
    
    Un algorithme A est un $\gamma$ apprenant faible (weak learner) pour une classe $\mathcal{H}$
    s'il existe une fonction $m_{\mathcal{H}}: (0,1) \rightarrow \mathbb{N}$ tel que 
    $\forall \delta \in (0,1)$, pour toute distribution $\mathcal{D}$ sur $\mathcal{X}$ et pour
    chaque fonction $f:\mathcal{X} \rightarrow \{\pm 1\}$,
    si ... blablabla
    l'algorithme retourne une hypotèse \textit{h} tel que $1- \delta, L_{(\mathcal{D}, f)}(H) \leq
    \frac{1}{2} - \gamma$

    Une classe d'hypothèses $\mathcal{H}$ est $\gamma$-weak-lernable s'il existe un 
    $\gamma$ apprenant faible pour cette classe.





\section{Adaboost}
 The AdaBoost algorithm
outputs a hypothesis that is a linear combination of simple hypotheses
AdaBoost enables us to control the tradeo between the approximation and estimation errors by
varying a single parameter.

\end{document}